# -*- coding: utf-8 -*-
"""CNN_handwritten.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qdZgq_DQxaufJpSn4uh18uyLlmp1hEGg
"""

import keras
import numpy as np
from keras.utils import to_categorical
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras.models import Sequential, Input, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU

from keras.datasets import mnist
from keras import backend as K

from keras.models import model_from_json

K.set_image_dim_ordering('th')

(train_x, train_y), (test_x, test_y) = mnist.load_data();

print('Training data shape', train_x.shape, train_y.shape)
print('Testing data shape', test_x.shape, test_y.shape)

classes = np.unique(train_y)
nClasses = len(classes)

print('Total number of classes:', nClasses)
print('Classes: ', classes)

plt.figure(figsize=[5, 5])

# Display the first image in training data
plt.subplot(121)  # subplot(2,1,1)
plt.imshow(train_x[0, :, :], cmap='gray')
plt.title("Ground Truth : {}".format(train_y[0]))
#plt.show()

# Display the first image in testing data
plt.subplot(122)
plt.imshow(test_x[0, :, :], cmap='gray')
plt.title("Ground Truth : {}".format(test_y[0]))
#plt.show()

"""""
Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1
3D matrices.

Keras requires an extra dimension in the end which correspond to channels.
MNIST images are gray scaled so it use only one channel.
For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.
"""""

train_x = train_x.reshape(-1, 28, 28, 1)
test_x = test_x.reshape(-1, 28, 28, 1)
print(train_x.shape, test_x.shape)

"""""
The data right now is in an int8 format, so before you feed it into the network you need to convert its type to float32, 
and you also have to rescale the pixel values in range 0 - 1 inclusive. So let's do that!

"""

train_x = train_x.astype('float32')
test_x = test_x.astype('float32')
train_x = train_x / 255.
test_x = test_x / 255.

"""""
Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]).
"""

train_y_one_hot = to_categorical(train_y)
test_y_one_hot = to_categorical(train_x)
print('Original label: ', train_y[0])
print('after conversation to one hot', train_y_one_hot[0])

train_x, valid_X, train_label, valid_label = train_test_split(train_x, train_y_one_hot, test_size=0.2)
print(train_x.shape, valid_X.shape, train_label.shape, valid_label.shape)

### TRAINING THE DATA

batch_size = 64
epochs = 1
num_classes = 10

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', input_shape=(28, 28, 1), padding='same'))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D((2, 2), padding='same'))
model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
model.add(Flatten())
model.add(Dense(128, activation='linear'))
model.add(LeakyReLU(alpha=0.1))
model.add(Dense(num_classes, activation='softmax'))

###

###### COMPILING THE MODEL

model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),
                      metrics=['accuracy'])

model.summary()

model_train = model.fit(train_x, train_label, batch_size=batch_size, epochs=epochs, verbose=1,
                                  validation_data=(valid_X, valid_label))

### Saving the model

model_jason = model.to_json()

with open("/Users/keyadesai/Desktop/capsNet/model.json","w") as json_file:
    json_file.write(model_jason)

print("saved model to disk")

""""
from google.colab import files
import cv2


uploaded = files.upload()
for fn in uploaded.keys():
       print('User uploaded file "{name}" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))

img_pred = cv2.imread(uploaded, 0)
# forces the image to have the input dimensions equal to those used in the training data (28x28)


if img_pred.shape ! = [ 28 , 28 ] :
img2 = cv2.resize(img_pred, (28, 28))
img_pred = img2.reshape(28, 28, - 1);
else :
   img_pred = img_pred. reshape ( 28 , 28 , - 1 ) ;

cv2.imshow("original", img_pred)
cv2.waitKey(0)

# here also we inform the value for the depth = 1, number of rows and columns, which correspond 28x28 of the image.
img_pred = img_pred.reshape(1, 1, 28, 28)
pred = model.predict_classes(img_pred)
pred = model.predict(img_pred)
pred_proba = model.predict_proba(img_pred)
pred_proba = "% .2f %%" % (pred_proba[0][pred] * 100)
print(pred[0], "with probability of", pred_proba)



"""